{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876ab60-d2e8-4de2-ab90-dc53c78bc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class SegmentationEvaluator:\n",
    "    def __init__(self, model, test_loader, threshold=0.6, device=None):\n",
    "        self.model = model.to(device)\n",
    "        self.test_loader = test_loader\n",
    "        self.threshold = threshold\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Diccionario de m√©tricas\n",
    "        self.metrics_funcs = {\n",
    "            \"Dice Coefficient\": self.dice_coefficient,\n",
    "            \"IoU Score\": self.iou_score,\n",
    "            \"Precision\": self.precision,\n",
    "            \"Sensitivity (Recall)\": self.recall,\n",
    "            \"Specificity\": self.specificity,\n",
    "            \"Accuracy\": self.accuracy,\n",
    "            \"F1-Score\": self.f1_score,\n",
    "            \"AUC\": self.auc_score,\n",
    "            \"Hausdorff Distance\": self.hausdorff_distance  # new metric 2025 fer\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def dice_coefficient(preds, labels):\n",
    "        preds = preds.float()\n",
    "        labels = labels.float()\n",
    "        intersection = (preds * labels).sum()\n",
    "        union = preds.sum() + labels.sum()\n",
    "        return (2.0 * intersection / (union + 1e-8)).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def iou_score(preds, labels):\n",
    "        preds = preds.float()\n",
    "        labels = labels.float()\n",
    "        intersection = (preds * labels).sum()\n",
    "        union = preds.sum() + labels.sum() - intersection\n",
    "        return (intersection / (union + 1e-8)).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def precision(preds, labels):\n",
    "        preds = preds.float()\n",
    "        labels = labels.float()\n",
    "        tp = (preds * labels).sum()\n",
    "        fp = (preds * (1 - labels)).sum()\n",
    "        return (tp / (tp + fp + 1e-8)).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def recall(preds, labels):\n",
    "        preds = preds.float()\n",
    "        labels = labels.float()\n",
    "        tp = (preds * labels).sum()\n",
    "        fn = ((1 - preds) * labels).sum()\n",
    "        return (tp / (tp + fn + 1e-8)).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def specificity(preds, labels):\n",
    "        preds = preds.float()\n",
    "        labels = labels.float()\n",
    "        tn = ((1 - preds) * (1 - labels)).sum()\n",
    "        fp = (preds * (1 - labels)).sum()\n",
    "        return (tn / (tn + fp + 1e-8)).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(preds, labels):\n",
    "        preds = preds.float()\n",
    "        labels = labels.float()\n",
    "        correct = (preds == labels).sum()\n",
    "        total = labels.numel()\n",
    "        return (correct / total).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def f1_score(preds, labels):\n",
    "        precision = SegmentationEvaluator.precision(preds, labels)\n",
    "        recall = SegmentationEvaluator.recall(preds, labels)\n",
    "        return 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    @staticmethod\n",
    "    def auc_score(preds, labels):\n",
    "        preds = preds.view(-1).cpu().numpy()\n",
    "        labels = labels.view(-1).cpu().numpy()\n",
    "    \n",
    "        # Verificar si hay al menos dos clases presentes\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            return 0.5  # AUC no computable, predeterminado a 0.5\n",
    "    \n",
    "        try:\n",
    "            return roc_auc_score(labels, preds)\n",
    "        except ValueError:\n",
    "            # Si ocurre otro error, devuelve 0.5\n",
    "            return 0.5\n",
    "    @staticmethod\n",
    "    def hausdorff_distance(preds, labels):\n",
    "        preds_np = preds.cpu().numpy().astype(np.bool_)\n",
    "        labels_np = labels.cpu().numpy().astype(np.bool_)\n",
    "    \n",
    "        distances = []\n",
    "        for pred, label in zip(preds_np, labels_np):\n",
    "            pred_coords = np.column_stack(np.where(pred[0]))\n",
    "            label_coords = np.column_stack(np.where(label[0]))\n",
    "    \n",
    "            if pred_coords.size == 0 or label_coords.size == 0:\n",
    "                distances.append(0.0)\n",
    "            else:\n",
    "                forward_hd = directed_hausdorff(pred_coords, label_coords)[0]\n",
    "                backward_hd = directed_hausdorff(label_coords, pred_coords)[0]\n",
    "                distances.append(max(forward_hd, backward_hd))\n",
    "    \n",
    "        return np.mean(distances)\n",
    "        \n",
    "    def evaluate(self, visualize=False, num_images=2):\n",
    "        self.model.eval()\n",
    "        metrics = {key: 0 for key in self.metrics_funcs.keys()}\n",
    "        num_batches = len(self.test_loader)\n",
    "\n",
    "        all_images = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                #print(\"MAx of outputs\", np.max(outputs))\n",
    "                preds_bin = torch.sigmoid(outputs)\n",
    "                #print(\"Max of preds bin\", np.max(preds_bin))\n",
    "                preds_bin = (outputs > self.threshold).float()\n",
    "\n",
    "                for key, func in self.metrics_funcs.items():\n",
    "                    if key == \"AUC\":\n",
    "                        metrics[key] += func(preds_bin, labels)  # AUC usa las predicciones continuas\n",
    "                    else:\n",
    "                        metrics[key] += func(preds_bin, labels)\n",
    "\n",
    "                if visualize:\n",
    "                    all_images.append(images.cpu())\n",
    "                    all_preds.append(preds_bin.cpu())\n",
    "                    all_labels.append(labels.cpu())\n",
    "\n",
    "        metrics = {k: v / num_batches for k, v in metrics.items()}\n",
    "\n",
    "        if visualize:\n",
    "            self.visualize_results(all_images, all_preds, all_labels, num_images)\n",
    "\n",
    "        print(metrics)\n",
    "        #wandb.log(metrics)\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_results(images, preds, labels, num_images=2):\n",
    "        images = torch.cat(images)[:num_images]\n",
    "        preds = torch.cat(preds)[:num_images]\n",
    "        labels = torch.cat(labels)[:num_images]\n",
    "\n",
    "        num_rows = num_images\n",
    "        plt.figure(figsize=(10, 3 * num_rows))\n",
    "\n",
    "        for i in range(num_images):\n",
    "            image = images[i].squeeze(0).numpy() \n",
    "            pred = preds[i].squeeze(0).numpy()\n",
    "            label = labels[i].squeeze(0).numpy()\n",
    "\n",
    "            plt.subplot(num_rows, 3, i * 3 + 1)\n",
    "            plt.imshow(image, cmap=\"gray\")\n",
    "            plt.title(\"Input Image\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(num_rows, 3, i * 3 + 2)\n",
    "            plt.imshow(pred, cmap=\"gray\")\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(num_rows, 3, i * 3 + 3)\n",
    "            plt.imshow(label, cmap=\"gray\")\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
