{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c054ca-ac34-4afc-bd5f-9d15b1475116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "import wandb\n",
    "\n",
    "class UNetTrainer:\n",
    "    def __init__(self, model, device, optimizer, criterion, train_loader, val_loader=None, test_loader=None, \n",
    "                 lr_step_size=10, lr_gamma=0.1, epochs=10, filename_model = 'best_model.pth', folder_pretrained= 'pretrained_model/'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.epochs = epochs\n",
    "        self.lr_step_size = lr_step_size\n",
    "        self.lr_gamma = lr_gamma\n",
    "        self.filename_model = filename_model\n",
    "        self.folder_pretrained = folder_pretrained\n",
    "        # Learning rate scheduler only for SGD\n",
    "        self.scheduler = None\n",
    "        if isinstance(self.optimizer, optim.SGD):\n",
    "            self.scheduler = CyclicLR(optimizer, base_lr=0.001, max_lr=0.1, step_size_up=lr_step_size, mode='triangular')\n",
    "\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_wts = self.model.state_dict()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = self._train_one_epoch()\n",
    "            \n",
    "            val_loss = self._validate() if self.val_loader else None\n",
    "\n",
    "            if val_loss is not None:\n",
    "                print(f\"Epoch [{epoch+1}/{self.epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            else:\n",
    "                print(f\"Epoch [{epoch+1}/{self.epochs}] - Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "                print(f\"Learning Rate: {self.scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss is not None and val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_wts = self.model.state_dict()\n",
    "                torch.save(self.best_model_wts, self.folder_pretrained+ self.filename_model)\n",
    "                print(f\"New best model saved with Val Loss: {self.best_val_loss:.4f}\")\n",
    "\n",
    "            # Log to Weights & Biases (wandb)\n",
    "            wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
    "\n",
    "        print(\"Training completed.\")\n",
    "        self.model.load_state_dict(self.best_model_wts)\n",
    "        print(\"Loaded best model weights.\")\n",
    "\n",
    "    def _train_one_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        for images, masks in self.train_loader:\n",
    "            images, masks = images.to(self.device), masks.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        return running_loss / len(self.train_loader)\n",
    "\n",
    "    def _validate(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in self.val_loader:\n",
    "                images, masks = images.to(self.device), masks.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, masks)\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        return running_loss / len(self.val_loader)\n",
    "\n",
    "    def test(self):\n",
    "        if not self.test_loader:\n",
    "            raise ValueError(\"Test DataLoader not provided.\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_images, all_preds, all_targets = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in self.test_loader:\n",
    "                images, masks = images.to(self.device), masks.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                \n",
    "                all_images.append(images.cpu())\n",
    "                all_preds.append(outputs.cpu())\n",
    "                all_targets.append(masks.cpu())\n",
    "\n",
    "        return torch.cat(all_images, dim=0), torch.cat(all_preds, dim=0), torch.cat(all_targets, dim=0)\n",
    "        \n",
    "    @staticmethod\n",
    "    def compute_model_stats(model, input_tensor):\n",
    "        # Compute FLOPs\n",
    "        flop_count = FlopCountAnalysis(model, input_tensor)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "        #print(f\"FLOPs: {flop_count.total():,}\")  # Print FLOPs with formatting\n",
    "        print(f\"Total Parameters: {total_params:,}\")\n",
    "        print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "\n",
    "        return flop_count, total_params, trainable_params\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_results(images, targets, preds, num_samples=3):\n",
    "        for i in range(num_samples):\n",
    "            image = images[i].numpy()\n",
    "            target = targets[i].squeeze(0).numpy()\n",
    "            pred = preds[i].squeeze(0).numpy()\n",
    "            pred_binary = (pred > 0.5).astype(np.uint8)\n",
    "\n",
    "            if image.shape[0] == 1:\n",
    "                image = image.squeeze(0)  \n",
    "            elif image.shape[0] == 3:\n",
    "                image = image.transpose(1, 2, 0)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            axs[0].imshow(image, cmap=\"gray\" if image.ndim == 2 else None)\n",
    "            axs[0].set_title(\"Original Image\")\n",
    "            axs[0].axis('off')  # Hide axes\n",
    "\n",
    "            axs[1].imshow(target, cmap=\"gray\")\n",
    "            axs[1].set_title(\"Ground Truth\")\n",
    "            axs[1].axis('off')  # Hide axes\n",
    "\n",
    "            axs[2].imshow(pred_binary, cmap=\"gray\")\n",
    "            axs[2].set_title(\"Prediction\")\n",
    "            axs[2].axis('off')  # Hide axes\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "    def save_model_wanDB(self):\n",
    "        torch.save(self.model.state_dict(), self.folder_pretrained+ self.filename_model)\n",
    "        wandb.save(self.folder_pretrained+ self.filename_model)\n",
    "        print(\"Model saved and uploaded to WandB\")\n",
    "        \n",
    "    def evaluate_metrics(self, threshold=0.1):\n",
    "            evaluator = SegmentationEvaluator(self.model, self.test_loader, threshold= 0.1, device=self.device)\n",
    "            metrics = evaluator.evaluate(visualize=False)\n",
    "            print(metrics)\n",
    "            wandb.log(metrics)  # Log the metrics to WandB\n",
    "            return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
