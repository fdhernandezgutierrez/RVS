{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37683aa2-43cb-490f-8a35-7da53e481618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import cv2 \n",
    "from skimage.filters import frangi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4021e156-e3fd-4c5c-a4a0-b21a742f312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(base_dir, img_folder, mask_folder, img_ext=\".jpg\", mask_ext=\".tif\", mask_suffix=\"\"):\n",
    "    images, masks = [], []\n",
    "\n",
    "    img_dir = os.path.join(base_dir, img_folder)\n",
    "    mask_dir = os.path.join(base_dir, mask_folder)\n",
    "\n",
    "    for img_name in os.listdir(img_dir):\n",
    "        if img_name.endswith(img_ext): # DRIVE dataset\n",
    "            img_path = img_dir+'/'+ img_name\n",
    "            print(img_path)\n",
    "            mask_name = img_name.replace('_training.tif', '_manual1.gif') \n",
    "            #mask_name = img_name.replace('.jpg','_1stHO.png') \n",
    "            #mask_name = img_name.replace('.JPG','.tif') \n",
    "\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            print('mask path',mask_path)\n",
    "\n",
    "\n",
    "            if os.path.exists(mask_path): \n",
    "                images.append(Image.open(img_path))\n",
    "                masks.append(Image.open(mask_path))\n",
    "                \n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def apply_retinex(image, sigma_list=[2, 5, 10]):\n",
    "    retinex = np.zeros_like(image, dtype=np.float32)\n",
    "    for sigma in sigma_list:\n",
    "        retinex += np.log1p(image) - np.log1p(cv2.GaussianBlur(image, (0, 0), sigma))\n",
    "    retinex = retinex / len(sigma_list)\n",
    "    return np.uint8(255 * (retinex - retinex.min()) / (retinex.max() - retinex.min()))\n",
    "\n",
    "\n",
    "def apply_clahe(image, clip_limit=4.0, tile_grid_size=(32, 32)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    return clahe.apply(image)\n",
    "\n",
    "\n",
    "def apply_gamma_correction(image, gamma=1.0):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "\n",
    "def apply_frangi(image):\n",
    "    image_normalized = image / 255.0\n",
    "    frangi_image = frangi(image_normalized)\n",
    "    return np.uint8(255 * (frangi_image - frangi_image.min()) / (frangi_image.max() - frangi_image.min()))\n",
    "\n",
    "\n",
    "class ConsistentRotation:\n",
    "    def __init__(self, angles=[0, 15, 30, 45, 90, 100, 120], p=1.0):\n",
    "        self.angles = angles\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, mask):\n",
    "        if random.random() < self.p:\n",
    "            angle = random.choice(self.angles)\n",
    "            img = img.rotate(angle)\n",
    "            mask = mask.rotate(angle)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RetinalVesselDataset(Dataset):\n",
    "    def __init__(self, folder_path, dataset_name='drive', transform=None, mask_transform=None, gamma=1.0, clahe_clip_limit=4.0, clahe_tile_grid_size=(32, 32)):\n",
    "        dataset_loaders = {\n",
    "            'drive': lambda: load_dataset(folder_path, 'training/images', 'training/1st_manual', '.tif', '.gif', '_manual1'),\n",
    "            'chase': lambda: load_dataset(folder_path, 'Images', 'Masks', '.jpg', '.png', '_1stHO'),\n",
    "            'hrf': lambda: load_dataset(folder_path, 'images', 'manual1', '.JPG', '.tif')\n",
    "        }\n",
    "\n",
    "        if dataset_name not in dataset_loaders:\n",
    "            raise ValueError(f\"Dataset {dataset_name} no recognized. Use: 'drive', 'chase' o 'hrf'.\")\n",
    "\n",
    "        self.images, self.masks = dataset_loaders[dataset_name]()\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.rotation = ConsistentRotation()\n",
    "        self.gamma = gamma\n",
    "        self.clahe_clip_limit = clahe_clip_limit\n",
    "        self.clahe_tile_grid_size = clahe_tile_grid_size  # Ahora configurable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask   = self.images[idx], self.masks[idx]\n",
    "        green_channel = np.array(image)[:, :, 1]\n",
    "        green_channel = apply_gamma_correction(green_channel, gamma=self.gamma)\n",
    "        green_channel = apply_clahe(green_channel, clip_limit=self.clahe_clip_limit, tile_grid_size=self.clahe_tile_grid_size)\n",
    "        image         = Image.fromarray(green_channel)\n",
    "        image, mask   = self.rotation(image, mask)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask  = self.transform(mask)\n",
    "\n",
    "        #if self.mask_transform:\n",
    "        #    mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb8c52-fa78-40e2-930f-8dccb025c3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
